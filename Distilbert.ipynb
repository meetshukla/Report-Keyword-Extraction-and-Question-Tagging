{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0er2-5l0tWKd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 01:35:35.957510: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from transformers import DistilBertModel, DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics import Accuracy, F1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbXYSZXBtYkZ"
   },
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rYeacknutYVr"
   },
   "outputs": [],
   "source": [
    "data_dir = \"Data/\" # \"drive/MyDrive/COMP 5505 O/Project/Data/\"\n",
    "\n",
    "x_train = pd.read_csv(data_dir + \"x_train_final.csv\")[\"question\"].to_numpy()\n",
    "x_test = pd.read_csv(data_dir + \"x_val_final.csv\")[\"question\"].to_numpy()\n",
    "\n",
    "\n",
    "y_train = load_npz(data_dir + \"y_train_final.npz\").toarray()\n",
    "y_test = load_npz(data_dir + \"y_val_final.npz\").toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u58iy4CptbDc",
    "outputId": "647574de-43b0-4eee-9e01-470eb4c98219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77733,) (77733, 500) (19433,) (19433, 500) (19433,) (19433, 500)\n"
     ]
    }
   ],
   "source": [
    "final_train_size = x_train.shape[0] // 5\n",
    "final_test_size = x_test.shape[0] // 5\n",
    "\n",
    "x_train_final = x_train[:final_train_size]\n",
    "y_train_final = y_train[:final_train_size]\n",
    "\n",
    "x_val_final = x_test[:final_test_size]\n",
    "y_val_final = y_test[:final_test_size]\n",
    "\n",
    "x_test_final = x_test[-final_test_size:]\n",
    "y_test_final = y_test[-final_test_size:]\n",
    "\n",
    "print(x_train_final.shape, y_train_final.shape, x_val_final.shape, y_val_final.shape, x_test_final.shape, y_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_3obso3tdw1"
   },
   "source": [
    "### Models and DataLoader functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "533GDcccteGV"
   },
   "outputs": [],
   "source": [
    "class QTagDataset(Dataset):\n",
    "    def __init__(self,quest,tags, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = quest\n",
    "        self.labels = tags\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, item_idx):\n",
    "        text = self.text[item_idx]\n",
    "        inputs = self.tokenizer.encode_plus(text, None, add_special_tokens=True, max_length= self.max_len, \n",
    "                                            padding = \"max_length\", return_token_type_ids= False, \n",
    "                                            return_attention_mask= True, truncation=True, return_tensors = \"pt\")\n",
    "        \n",
    "        input_ids = inputs[\"input_ids\"].flatten()\n",
    "        attn_mask = inputs[\"attention_mask\"].flatten()\n",
    "               \n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attn_mask, \"labels\": torch.tensor(self.labels[item_idx], dtype=torch.float)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class QTagDataModule (pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, x_train, y_train, x_val, y_val, x_test, y_test, tokenizer, batch_size=16, max_token_len=200):\n",
    "            super().__init__()\n",
    "            self.tr_text = x_train\n",
    "            self.tr_label = y_train\n",
    "            self.val_text = x_val\n",
    "            self.val_label = y_val\n",
    "            self.test_text = x_test\n",
    "            self.test_label = y_test\n",
    "            self.tokenizer = tokenizer\n",
    "            self.batch_size = batch_size\n",
    "            self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = QTagDataset(quest=self.tr_text,  tags=self.tr_label, tokenizer=self.tokenizer, max_len= self.max_token_len)\n",
    "        self.val_dataset= QTagDataset(quest=self.val_text, tags=self.val_label, tokenizer=self.tokenizer, max_len = self.max_token_len)\n",
    "        self.test_dataset =QTagDataset(quest=self.test_text, tags=self.test_label, tokenizer=self.tokenizer, max_len = self.max_token_len)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,batch_size= self.batch_size, shuffle = True , num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader (self.val_dataset,batch_size= 16)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader (self.test_dataset,batch_size= 16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class QTagDistilBert(pl.LightningModule):\n",
    "    def __init__(self, model_path_or_name, n_classes = 500, steps_per_epoch = None, n_epochs = 3, lr = 2e-5, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.distilbert = DistilBertForSequenceClassification.from_pretrained(model_path_or_name, num_labels=n_classes)\n",
    "        #self.classifier= nn.Linear(self.distilbert.config.hidden_size, n_classes)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self,input_ids, attn_mask, labels=None):\n",
    "        output = self.distilbert(input_ids=input_ids,attention_mask=attn_mask, labels=labels)\n",
    "        #output = self.classifier(output.last_hidden_state)\n",
    "        return output[\"loss\"], output[\"logits\"]\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    # def training_epoch_end(self, outputs):\n",
    "    #     labels = []\n",
    "    #     predictions = []\n",
    "    #     for output in outputs:\n",
    "    #         for out_labels in output[\"labels\"].detach().cpu():\n",
    "    #             labels.append(out_labels)\n",
    "    #         for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "    #             predictions.append(out_predictions)\n",
    "        \n",
    "    #     labels = torch.stack(labels).int()\n",
    "    #     predictions = torch.stack(predictions)\n",
    "    #     for i in range(500):\n",
    "    #         class_accuracy = Accuracy(predictions[:, i], labels[:, i])\n",
    "    #         self.logger.experiment.add_scalar(\"Tag (\" + str(i) + \")_accuracy/Train\", class_accuracy, self.current_epoch)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = self.n_warmup_steps, \n",
    "                                                    num_training_steps=self.n_training_steps)\n",
    "\n",
    "        return dict(optimizer=optimizer, lr_scheduler=dict(scheduler=scheduler, interval='step'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6CYTk6TtkLd"
   },
   "source": [
    "### Initializing DistilBERT, Tokenizer, and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kocHDgDRthYD"
   },
   "outputs": [],
   "source": [
    "distilbert_save_path = \"results/trained_models/distilbert/\"# \"drive/MyDrive/COMP 5505 O/Project/results/trained_models/DistilBert/\"\n",
    "\n",
    "if not os.path.exists(distilbert_save_path):\n",
    "    os.makedirs(distilbert_save_path)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(dirpath = distilbert_save_path, monitor=\"val_loss\", filename=\"QTag-{epoch:02d}-{val_loss:.2f}\", save_top_k=3,\n",
    "                                      mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4uUN2ZMPtnF6"
   },
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "batch_size = 4\n",
    "max_len = 512\n",
    "lr = 2e-05\n",
    "\n",
    "steps_per_epoch = x_train.shape[0] // batch_size\n",
    "total_training_steps = steps_per_epoch * n_epochs\n",
    "warmup_steps = total_training_steps // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0mn-6uQtpT6",
    "outputId": "1fa07b2e-4255-446b-f6b1-33f4446dc1c7"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03528428077697754,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 28,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a837b82f0144de93ddff38824be95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.029314756393432617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc21b5a69a9a41d3a705191a547a1b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024489402770996094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 466062,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87017c3812146cb81eba4bbca7a43ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02710413932800293,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 483,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37aeadfc71fa41828df0ee962ca862c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026007652282714844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 267967963,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd2fea3e9f14f0cb5a933e3ee7f50a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "distilbert_tokenizer = DistilBertTokenizerFast.from_pretrained(\"deberta-v3-base\")\n",
    "distilbert_pretrained = \"deberta-v3-base\"\n",
    "\n",
    "model = QTagDeBerta(model_path_or_name = distilbert_pretrained, n_classes = 500, steps_per_epoch = steps_per_epoch, n_epochs = n_epochs, lr = lr, \n",
    "                 n_training_steps = total_training_steps, n_warmup_steps = warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aOipsU6Etqiq"
   },
   "outputs": [],
   "source": [
    "QT_data_module = QTagDataModule(x_train = x_train_final, y_train = y_train_final, x_val = x_val_final, y_val = y_val_final, x_test = x_test_final, y_test = y_test_final, \n",
    "                                tokenizer = distilbert_tokenizer, batch_size = batch_size, max_token_len = max_len)\n",
    "QT_data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofFPsN44tr-_"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0zzYLUEttR6",
    "outputId": "f0619bf5-4cb5-457d-b8f7-b3e5c833a9b2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus = 1, max_epochs = 3, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364,
     "referenced_widgets": [
      "3373947d776147e7ad6075b4bbbae397",
      "38dd97f6b8a64c6da2c133293564da1f",
      "4e444ff8a5b94817bcf4da6c0063f98a",
      "2c407e1698794954816dd8c0b85d3615",
      "177983d8c13a4f5fa828cf3b2a121f00",
      "c239afb8824a42be9efaf9c89c9ab36d",
      "1a20b0cd34464ec389dc599c4009fb25",
      "7ec24f3e15e14b09a460144b0c64e7f5",
      "90c0db601e4f46979c37508d11e048c9",
      "600afe0cebee4f9895303c5194e61109",
      "5bf7787bed8f44dc9b2e4102d2b33141",
      "0dcba384bccc4733829398f26af0d2e1",
      "c4e7dfa9c2eb4633ae4724369bda543e",
      "baf71d77fdff437daea8375fea5ea7ba",
      "5bdb331fd4354d4cb8f51f10f4ffaddf",
      "fd6c7f09bf664fb78e4645507465de27",
      "3697f4a37bdc4209a6148ada09920031",
      "16611e7e0be644c6aeb491104c11642c",
      "1f63a00085b4454791bfe66f59fc3052",
      "9ec90775a2c142d7b947d1774306676f",
      "e2b7f4da6729405dac522dbe61dfd67e",
      "f6693b52ce5a49f09b0e7401fb7081ca"
     ]
    },
    "id": "9Kl6iPkDtvlq",
    "outputId": "c47c47de-375a-4b70-f2bf-8357ae3909d4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /home/student/COMP 5505 O - NLP/Project/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/student/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name       | Type                                | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | distilbert | DistilBertForSequenceClassification | 67.3 M\n",
      "1 | criterion  | BCEWithLogitsLoss                   | 0     \n",
      "-------------------------------------------------------------------\n",
      "67.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "67.3 M    Total params\n",
      "269.352   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.028189420700073242,
       "initial": 0,
       "n": 0,
       "ncols": 80,
       "nrows": 24,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02689385414123535,
       "initial": 0,
       "n": 0,
       "ncols": 80,
       "nrows": 24,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fe63b0cf74473196ba31b9c1e9269c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02762579917907715,
       "initial": 0,
       "n": 0,
       "ncols": 80,
       "nrows": 24,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027116775512695312,
       "initial": 0,
       "n": 0,
       "ncols": 80,
       "nrows": 24,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027940988540649414,
       "initial": 0,
       "n": 0,
       "ncols": 80,
       "nrows": 24,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model = model, datamodule = QT_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_pKzUE8L8-H9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.save(model, distilbert_save_path + \"distilbert_model\")\n",
    "    print(\"Model saved!\")\n",
    "except:\n",
    "    torch.save(model.state_dict(), distilbert_save_path + \"distilbert_model\")\n",
    "    print(\"Model weights saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUrGYTYYtw_N"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfEcIFRH9i6h"
   },
   "source": [
    "##### On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "J3zKv2df9HP1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_save_path = \"results/trained_models/distilbert/\" # \"drive/MyDrive/COMP 5505 O/Project/results/trained_models/DistilBert/\"\n",
    "\n",
    "distilbert_tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "distilbert_pretrained = \"distilbert-base-uncased\"\n",
    "\n",
    "fine_tuned_model = QTagDistilBert(model_path_or_name = distilbert_pretrained, n_classes = 500, steps_per_epoch = steps_per_epoch, n_epochs = n_epochs, lr = lr, \n",
    "                                  n_training_steps = total_training_steps, n_warmup_steps = warmup_steps)\n",
    "\n",
    "\n",
    "fine_tuned_model.load_state_dict(torch.load(distilbert_save_path + \"distilbert_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "E2mmHVkr9dcr"
   },
   "outputs": [],
   "source": [
    "fine_tuned_model.eval()\n",
    "\n",
    "QT_data_module = QTagDataModule(x_train = x_train_final, y_train = y_train_final, x_val = x_val_final, y_val = y_val_final, x_test = x_test_final, y_test = y_test_final, \n",
    "                                tokenizer = distilbert_tokenizer, batch_size = batch_size, max_token_len = max_len)\n",
    "QT_data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0H0J-1Uttx__"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/student/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019826889038085938,
       "initial": 0,
       "n": 0,
       "ncols": 80,
       "nrows": 24,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564bf9eb381c431d84e5e8d73ec3e625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.010209504514932632\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "test_loss = trainer.test(fine_tuned_model, datamodule = QT_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3UR-a4I_9too"
   },
   "outputs": [],
   "source": [
    "accuracy_fn = Accuracy(task = \"multilabel\", num_labels = 500)\n",
    "f1_score_fn = F1Score(task = \"multilabel\", num_labels = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "urTV1mJj9-2k"
   },
   "outputs": [],
   "source": [
    "def get_predictions(test_loader, model):\n",
    "    actual_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with tqdm(total=final_test_size, desc=\"Progress\") as pbar:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(test_loader):\n",
    "\n",
    "                preds = model(input_ids = batch[\"input_ids\"], attn_mask = batch[\"attention_mask\"], labels=batch[\"labels\"])\n",
    "                predictions.extend(preds[1].detach().cpu().numpy().tolist())\n",
    "                actual_labels.extend(batch[\"labels\"].detach().cpu().numpy().tolist())\n",
    "                pbar.update(batch[\"labels\"].detach().cpu().size()[0])\n",
    "\n",
    "    return torch.tensor(actual_labels), torch.tensor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0yYjpnNV-8Ok"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████| 19433/19433 [1:36:02<00:00,  3.37it/s]\n"
     ]
    }
   ],
   "source": [
    "y_test_labels, y_pred_test = get_predictions(QT_data_module.test_dataloader(), fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jEA_GWQg_EQG"
   },
   "outputs": [],
   "source": [
    "distilbert_accuracy = accuracy_fn(y_pred_test, y_test_labels)\n",
    "distilbert_f1_score = f1_score_fn(y_pred_test, y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uH6-4cI-_MuS",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "Accuracy:  0.99718666 \n",
      "F1-Score:  0.4351833\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation results:\\nAccuracy: \", distilbert_accuracy.numpy(), \"\\nF1-Score: \", distilbert_f1_score.numpy())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0dcba384bccc4733829398f26af0d2e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4e7dfa9c2eb4633ae4724369bda543e",
       "IPY_MODEL_baf71d77fdff437daea8375fea5ea7ba",
       "IPY_MODEL_5bdb331fd4354d4cb8f51f10f4ffaddf"
      ],
      "layout": "IPY_MODEL_fd6c7f09bf664fb78e4645507465de27"
     }
    },
    "16611e7e0be644c6aeb491104c11642c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "177983d8c13a4f5fa828cf3b2a121f00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "1a20b0cd34464ec389dc599c4009fb25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f63a00085b4454791bfe66f59fc3052": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c407e1698794954816dd8c0b85d3615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_600afe0cebee4f9895303c5194e61109",
      "placeholder": "​",
      "style": "IPY_MODEL_5bf7787bed8f44dc9b2e4102d2b33141",
      "value": " 2/? [00:00&lt;00:00, 16.25it/s]"
     }
    },
    "3373947d776147e7ad6075b4bbbae397": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_38dd97f6b8a64c6da2c133293564da1f",
       "IPY_MODEL_4e444ff8a5b94817bcf4da6c0063f98a",
       "IPY_MODEL_2c407e1698794954816dd8c0b85d3615"
      ],
      "layout": "IPY_MODEL_177983d8c13a4f5fa828cf3b2a121f00"
     }
    },
    "3697f4a37bdc4209a6148ada09920031": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38dd97f6b8a64c6da2c133293564da1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c239afb8824a42be9efaf9c89c9ab36d",
      "placeholder": "​",
      "style": "IPY_MODEL_1a20b0cd34464ec389dc599c4009fb25",
      "value": "Sanity Checking: "
     }
    },
    "4e444ff8a5b94817bcf4da6c0063f98a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ec24f3e15e14b09a460144b0c64e7f5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_90c0db601e4f46979c37508d11e048c9",
      "value": 1
     }
    },
    "5bdb331fd4354d4cb8f51f10f4ffaddf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2b7f4da6729405dac522dbe61dfd67e",
      "placeholder": "​",
      "style": "IPY_MODEL_f6693b52ce5a49f09b0e7401fb7081ca",
      "value": " 486/20649 [01:40&lt;1:09:47,  4.82it/s, loss=0.622, v_num=0, train_loss=0.617]"
     }
    },
    "5bf7787bed8f44dc9b2e4102d2b33141": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "600afe0cebee4f9895303c5194e61109": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ec24f3e15e14b09a460144b0c64e7f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90c0db601e4f46979c37508d11e048c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9ec90775a2c142d7b947d1774306676f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "baf71d77fdff437daea8375fea5ea7ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f63a00085b4454791bfe66f59fc3052",
      "max": 20649,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ec90775a2c142d7b947d1774306676f",
      "value": 486
     }
    },
    "c239afb8824a42be9efaf9c89c9ab36d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4e7dfa9c2eb4633ae4724369bda543e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3697f4a37bdc4209a6148ada09920031",
      "placeholder": "​",
      "style": "IPY_MODEL_16611e7e0be644c6aeb491104c11642c",
      "value": "Epoch 0:   2%"
     }
    },
    "e2b7f4da6729405dac522dbe61dfd67e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6693b52ce5a49f09b0e7401fb7081ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd6c7f09bf664fb78e4645507465de27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
